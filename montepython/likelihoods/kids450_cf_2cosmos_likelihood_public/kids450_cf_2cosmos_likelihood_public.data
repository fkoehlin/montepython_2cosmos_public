#####################################################################
# Data and precision parameters for the KiDS-450 correlation        #
# function '2cosmo' likelihood that allows to split the KiDS-450    #
# dataset into two mutually exclusive subsets with independent      #
# cosmological parameters and calculations. The subsets are still   #
# coupled through the joint covariance matrix.                      #
#                                                                   #
# To be used with data from Hildebrandt et al. 2017 (MNRAS, 465,    #
# 1454) available from:                                             #
#                                                                   #
# http://kids.strw.leidenuniv.nl/sciencedata.php                    #
#                                                                   #
# Please refer to Koehlinger et al. 2019 (MNRAS, 484, 3126) for the #
# application of this likelihood.                                   #
#                                                                   #
# ATTENTION:                                                        #
# 1) This likelihood does NOT work with the standard Monte Python   #
# but requires the modified '2cosmo' version available from:        #
#                                                                   #
# https://github.com/fkoehlin/montepython_2cosmos_public            #
#                                                                   #
# 2) This likelihood only produces valid results for \Omega_k = 0,  #
# i.e. flat cosmologies!                                            #
#####################################################################

### GENERAL SETTINGS ###

## DATA LOCATION ##

# Set the path to the folder 'KiDS-450_COSMIC_SHEAR_DATA_RELEASE' from the uncompressed tarball
# downloaded from http://kids.strw.leidenuniv.nl/sciencedata.php
kids450_cf_2cosmos_likelihood_public.data_directory = '/your/path/to/KiDS-450_COSMIC_SHEAR_DATA_RELEASE/'

## REDSHIFT DISTRIBUTIONS ##

# choose the calibration method for the redshift distributions from
# ['DIR', 'CC'], refer to the tarball's README for details!
default: 'DIR'
kids450_cf_2cosmos_likelihood_public.nz_method = 'DIR'

# number of discrete z-values used for all integrations, can be set to arbitrary numbers now
# default ( = resolution of histogram): 70
kids450_cf_2cosmos_likelihood_public.nzmax = 70

# set flag to marginalize over bootstrap errors of n(z) (only possible for 'DIR'):
# default: True
kids450_cf_2cosmos_likelihood_public.bootstrap_photoz_errors = True
# if above flag is set to True, then specify lowest and highest index of bootstrap realizations
# full range: ..._low = 1 and ..._high = 1000
kids450_cf_2cosmos_likelihood_public.index_bootstrap_low = 1
kids450_cf_2cosmos_likelihood_public.index_bootstrap_high = 1000

## SHEAR CALIBRATION UNCERTAINTY ##

# set to "True" if you want to marginalize over the uncertainty of the
# multiplicative shear calibration:
# default: True
kids450_cf_2cosmos_likelihood_public.marginalize_over_multiplicative_bias_uncertainty = True
# supply error for m-correction:
# default: 0.01
kids450_cf_2cosmos_likelihood_public.err_multiplicative_bias = 0.01

## MASKING ##

# Set flag to use angular mask (to cut on theta-scales per z-bin)
# default: True
# (since we load the data vector and covariance matrix for all measured scales)
kids450_cf_2cosmos_likelihood_public.use_cut_theta = True
# if True, select a cut scheme from the folder
# 'data_directory/CUT_VALUES/'(ATTENTION: you must copy that folder manually to
# 'data_directory/'!):
# the splits applied in Koehlinger et al. 2019 were the following ones:
# 1) large angular scales vs. small angular scales:
#kids450_cf_2cosmos_likelihood_public.cutvalues_file1 = 'cut_values_large_scales.txt'
#kids450_cf_2cosmos_likelihood_public.cutvalues_file2 = 'cut_values_small_scales.txt'
# 2) xi_p vs. xi_m:
#kids450_cf_2cosmos_likelihood_public.cutvalues_file1 = 'cut_values_xi_p.txt'
#kids450_cf_2cosmos_likelihood_public.cutvalues_file2 = 'cut_values_xi_m.txt'
# 3) z-bin{1, 2, 3, 4} (incl. all its cross-correlations) vs. all other z-bin correlations:
kids450_cf_2cosmos_likelihood_public.cutvalues_file1 = 'cut_values_fiducial.txt'
kids450_cf_2cosmos_likelihood_public.cutvalues_file2 = 'cut_values_zbin1.txt'
#kids450_cf_2cosmos_likelihood_public.cutvalues_file2 = 'cut_values_zbin2.txt'
#kids450_cf_2cosmos_likelihood_public.cutvalues_file2 = 'cut_values_zbin3.txt'
#kids450_cf_2cosmos_likelihood_public.cutvalues_file2 = 'cut_values_zbin4.txt'
# IMPORTANT: for cases 1) and 2) you must set the following flag to 'False'!
# For case 3), however, you must set the flag to 'True', so that mask2 is
# subtracted from mask1, e.g.:
# mask1 = cut_values_fiducial.txt
# mask2 = cut_values_zbin1.txt
# --> modified mask1 contains all other z-bin combos and mask2 all with z-bin1
#kids450_cf_2cosmos_likelihood_public.subtract_mask2_from_mask1 = False
kids450_cf_2cosmos_likelihood_public.subtract_mask2_from_mask1 = True

## PRECISION SETTINGS ##

# these settings set the precision of the Cl integration
# maximum l for C_l
# default: 60000
kids450_cf_2cosmos_likelihood_public.lmax = 60000

# logarithmic l step for C_l
# default: 0.4
kids450_cf_2cosmos_likelihood_public.dlnl = 0.4

# parameters controlling the precision of the integral
# for the correlation function (int l C_l J(x))
# through the stepsize of x == l * theta
# (this also controls the speed of the likelihood,
# since this integral is the bottleneck)
# default: 50.
kids450_cf_2cosmos_likelihood_public.xmax = 50.
# default: 0.05
kids450_cf_2cosmos_likelihood_public.dx_below_threshold = 0.05
# default: 0.15
kids450_cf_2cosmos_likelihood_public.dx_above_threshold = 0.15
# default: 0.4
kids450_cf_2cosmos_likelihood_public.dx_threshold = 0.4
# default: 0.25
kids450_cf_2cosmos_likelihood_public.dlntheta = 0.25

## METHOD FOR NON-LINEAR CORRECTIONS ##

# choose the method for calculation of non-linear corrections, any CLASS keyword
# is possible, but the default choice is: 'halofit'
kids450_cf_2cosmos_likelihood_public.method_non_linear_Pk = 'halofit'

# scale k_max (in h/Mpc) up to which the non-linear corrections (of the matter
# power spectrum) are used/trusted (set to zero for k > k_max):
# default: 100.
kids450_cf_2cosmos_likelihood_public.k_max_h_by_Mpc = 100.


### NUISANCE PARAMETERS ###

## BARYON FEEDBACK ##

# choose a baryonic feedback model (from OWLS): 'REF', 'AGN', 'DBLIM'
# default: 'AGN'
kids450_cf_2cosmos_likelihood_public.baryon_model = 'AGN'
# this allows to marginalize over a free baryon feedback amplitude A_bary:
# (i.e. it is simply modifying the amplitude set by the chosen model)
# default: ['A_bary1', 'A_bary2']
#kids450_cf_2cosmos_likelihood_public.use_nuisance = ['A_bary_1', 'A_bary_2']

## INTRINSIC ALIGNMENTS (IA) ###

# this allows to include IA:
# if only 'amp_IA' is passed, 'exp_IA' = 0 (i.e. redshift-scaling is turned off!)
# default: only use ['A_IA'] per split
#kids450_cf_2cosmos_likelihood_public.use_nuisance = ['A_IA_1', 'exp_IA_1', 'A_IA_2', 'exp_IA_2']
#kids450_cf_2cosmos_likelihood_public.use_nuisance = ['A_IA_1', 'A_IA_2']

## FULL LIST OF ALL NUISANCES ##

# combine all nuisance parameters in one list for marginalization:
# default: [A_bary_1, A_bary_2, A_IA_1, A_IA_2]
kids450_cf_2cosmos_likelihood_public.use_nuisance = ['A_bary_1', 'A_bary_2', 'A_IA_1', 'A_IA_2']

# if you want to use/marginalize over the same nuisance parameters for both data
# splits (i.e. one
# parameter for both data splits instead of two independent parameters per
# split), set this flag to 'True':
# default: False
kids450_cf_2cosmos_likelihood_public.use_joint_nuisance = False
# this is what 'use_nuisance' should look like if use_joint_nuisance = True:
# (i.e. no subscripts for common nuisances!)
#kids450_cf_2cosmos_likelihood_public.use_nuisance = ['A_bary', 'A_IA']